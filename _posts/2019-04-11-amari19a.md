---
title: Fisher Information and Natural Gradient Learning in Random Deep Networks
abstract: The parameter space of a deep neural network is a Riemannian manifold, where
  the metric is defined by the Fisher information matrix.  The natural gradient method
  uses the steepest descent direction in a Riemannian manifold, but it requires inversion
  of the Fisher matrix, however, which is practically difficult.  The present paper
  uses statistical neurodynamical method to reveal the properties of the Fisher information
  matrix in a net of random connections.  We prove that the Fisher information matrix
  is unit-wise block diagonal supplemented by small order terms of off-block-diagonal
  elements.  We further prove that the Fisher information matrix of a single unit
  has a simple reduced form, a sum of a diagonal matrix and a rank 2 matrix of weight-bias
  correlations.  We obtain the inverse of Fisher information explicitly.  We then
  have an explicit form of the approximate natural gradient, without relying on the
  matrix inversion.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: amari19a
month: 0
tex_title: Fisher Information and Natural Gradient Learning in Random Deep Networks
firstpage: 694
lastpage: 702
page: 694-702
order: 694
cycles: false
bibtex_author: Amari, Shun-ichi and Karakida, Ryo and Oizumi, Masafumi
author:
- given: Shun-ichi
  family: Amari
- given: Ryo
  family: Karakida
- given: Masafumi
  family: Oizumi
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/amari19a/amari19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
