---
title: Nearly Optimal Adaptive Procedure with Change Detection for Piecewise-Stationary
  Bandit
abstract: Multi-armed bandit (MAB) is a class of online learning problems where a
  learning agent aims to maximize its expected cumulative reward while repeatedly
  selecting to pull arms with unknown reward distributions. We consider a scenario
  where the reward distributions may change in a piecewise-stationary fashion at unknown
  time steps. We show that by incorporating a simple change-detection component with
  classic UCB algorithms to detect and adapt to changes, our so-called M-UCB algorithm
  can achieve nearly optimal regret bound on the order of $O(\sqrt{MKT\log T})$, where
  $T$ is the number of time steps, $K$ is the number of arms, and $M$ is the number
  of stationary segments.  Comparison with the best available lower bound shows that
  our M-UCB is nearly optimal in $T$ up to a logarithmic factor.  We also compare
  M-UCB with the state-of-the-art algorithms in numerical experiments using a public
  Yahoo! dataset and a real-world digital marketing dataset to demonstrate its superior
  performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cao19a
month: 0
tex_title: Nearly Optimal Adaptive Procedure with Change Detection for Piecewise-Stationary
  Bandit
firstpage: 418
lastpage: 427
page: 418-427
order: 418
cycles: false
bibtex_author: Cao, Yang and Wen, Zheng and Kveton, Branislav and Xie, Yao
author:
- given: Yang
  family: Cao
- given: Zheng
  family: Wen
- given: Branislav
  family: Kveton
- given: Yao
  family: Xie
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/cao19a/cao19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/cao19a/cao19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
