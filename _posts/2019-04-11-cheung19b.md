---
title: Learning to Optimize under Non-Stationarity
abstract: We introduce algorithms that achieve state-of-the-art dynamic regret bounds
  for non-stationary linear stochastic bandit setting. It captures natural applications
  such as dynamic pricing and ads allocation in a changing environment. We show how
  the difficulty posed by the non-stationarity can be overcome by a novel marriage
  between stochastic and adversarial bandits learning algorithms. Our main contributions
  are the tuned Sliding Window UCB (SW-UCB) algorithm with optimal dynamic regret,
  and the tuning free bandit-over-bandit (BOB) framework built on top of the SW-UCB
  algorithm with best (compared to existing literature) dynamic regret.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cheung19b
month: 0
tex_title: Learning to Optimize under Non-Stationarity
firstpage: 1079
lastpage: 1087
page: 1079-1087
order: 1079
cycles: false
bibtex_author: Cheung, Wang Chi and Simchi-Levi, David and Zhu, Ruihao
author:
- given: Wang Chi
  family: Cheung
- given: David
  family: Simchi-Levi
- given: Ruihao
  family: Zhu
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/cheung19b/cheung19b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/cheung19b/cheung19b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
