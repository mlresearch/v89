---
title: On Connecting Stochastic Gradient MCMC and Differential Privacy
abstract: Concerns related to data security and confidentiality have been raised when
  applying machine learning to real-world applications. Differential privacy provides
  a principled and rigorous privacy guarantee for machine learning models. While it
  is common to inject noise to design a model satisfying a required differential-privacy
  property, it is generally hard to balance the trade-off between privacy and utility.
  We show that stochastic gradient Markov chain Monte Carlo (SG-MCMC) – a class of
  scalable Bayesian posterior sampling algorithms – satisfies strong differential
  privacy, when carefully chosen stepsizes are employed. We develop theory on the
  performance of the proposed differentially-private SG-MCMC method. We conduct experiments
  to support our analysis, and show that a standard SG-MCMC sampler with minor modification
  can reach state-of-the-art performance in terms of both privacy and utility on Bayesian
  learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: li19a
month: 0
tex_title: On Connecting Stochastic Gradient MCMC and Differential Privacy
firstpage: 557
lastpage: 566
page: 557-566
order: 557
cycles: false
bibtex_author: Li, Bai and Chen, Changyou and Liu, Hao and Carin, Lawrence
author:
- given: Bai
  family: Li
- given: Changyou
  family: Chen
- given: Hao
  family: Liu
- given: Lawrence
  family: Carin
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/li19a/li19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/li19a/li19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
