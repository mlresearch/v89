---
title: Regularized Contextual Bandits
abstract: We consider the stochastic contextual bandit problem with additional regularization.
  The motivation comes from problems where the policy of the agent must be close to
  some baseline policy which is known to perform well on the task. To tackle this
  problem we use a nonparametric model and propose an algorithm  splitting the context
  space into bins, and solving simultaneously — and independently — regularized multi-armed
  bandit instances on each bin. We derive slow and fast rates of convergence, depending
  on the unknown complexity of the problem. We also consider a new relevant margin
  condition to get problem-independent convergence rates, ending up in intermediate
  convergence rates interpolating between the aforementioned slow and fast rates.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: fontaine19a
month: 0
tex_title: Regularized Contextual Bandits
firstpage: 2144
lastpage: 2153
page: 2144-2153
order: 2144
cycles: false
bibtex_author: Fontaine, Xavier and Berthet, Quentin and Perchet, Vianney
author:
- given: Xavier
  family: Fontaine
- given: Quentin
  family: Berthet
- given: Vianney
  family: Perchet
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/fontaine19a/fontaine19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/fontaine19a/fontaine19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
