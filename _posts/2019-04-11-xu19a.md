---
title: Variance reduction properties of the reparameterization trick
abstract: The reparameterization trick is widely used in variational inference as
  it yields more accurate estimates of the gradient of the variational objective than
  alternative approaches such as the score function method. Although there is overwhelming
  empirical evidence in the literature showing its success, there is relatively little
  research exploring why the reparameterization trick is so effective. We explore
  this under the idealized assumptions that the variational approximation is a mean-field
  Gaussian density and that the log of the joint density of the model parameters and
  the data is a quadratic function that depends on the variational mean. From this,
  we show that the marginal variances of the reparameterization gradient estimator
  are smaller than those of the score function gradient estimator. We apply the result
  of our idealized analysis to real-world examples.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: xu19a
month: 0
tex_title: Variance reduction properties of the reparameterization trick
firstpage: 2711
lastpage: 2720
page: 2711-2720
order: 2711
cycles: false
bibtex_author: Xu, Ming and Quiroz, Matias and Kohn, Robert and Sisson, Scott A.
author:
- given: Ming
  family: Xu
- given: Matias
  family: Quiroz
- given: Robert
  family: Kohn
- given: Scott A.
  family: Sisson
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/xu19a/xu19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
