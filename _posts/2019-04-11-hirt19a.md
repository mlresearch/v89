---
title: Scalable Bayesian Learning for State Space Models using Variational Inference
  with SMC Samplers
abstract: We present a scalable approach to performing approximate fully Bayesian
  inference in generic state space models. The proposed method is an alternative to
  particle MCMC that provides fully Bayesian inference of both the dynamic latent
  states and the static pa- rameters of the model. We build up on recent advances
  in computational statistics that combine variational methods with sequential Monte
  Carlo sampling and we demonstrate the advantages of performing full Bayesian inference
  over the static parameters rather than just performing variational EM approxima-
  tions. We illustrate how our approach enables scalable inference in multivariate
  stochastic volatility models and self-exciting point pro- cess models that allow
  for flexible dynamics in the latent intensity function.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hirt19a
month: 0
tex_title: Scalable Bayesian Learning for State Space Models using Variational Inference
  with SMC Samplers
firstpage: 76
lastpage: 86
page: 76-86
order: 76
cycles: false
bibtex_author: Hirt, Marcel and Dellaportas, Petros
author:
- given: Marcel
  family: Hirt
- given: Petros
  family: Dellaportas
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/hirt19a/hirt19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/hirt19a/hirt19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
