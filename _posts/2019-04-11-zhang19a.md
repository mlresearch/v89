---
title: Scalable Thompson Sampling via Optimal Transport
abstract: Thompson sampling (TS) is a class of algorithms for sequential decision-making,
  which requires maintaining a posterior distribution over a reward model. However,
  calculating exact posterior distributions is intractable for all but the simplest
  models. Consequently, how to computationally-efficiently approximate a posterior
  distribution is a crucial problem for scalable TS with complex models, such as neural
  networks. In this paper, we use distribution optimization techniques to approximate
  the posterior distribution, solved via Wasserstein gradient flows. Based on the
  framework, a principled particle-optimization algorithm is developed for TS to approximate
  the posterior efficiently. Our approach is scalable and does not make explicit distribution
  assumptions on posterior approximations.  Extensive experiments on both synthetic
  data and large-scale real data demonstrate the superior performance of the proposed
  methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhang19a
month: 0
tex_title: Scalable Thompson Sampling via Optimal Transport
firstpage: 87
lastpage: 96
page: 87-96
order: 87
cycles: false
bibtex_author: Zhang, Ruiyi and Wen, Zheng and Chen, Changyou and Fang, Chen and Yu,
  Tong and Carin, Lawrence
author:
- given: Ruiyi
  family: Zhang
- given: Zheng
  family: Wen
- given: Changyou
  family: Chen
- given: CHEN
  family: FANG
- given: Tong
  family: Yu
- given: Lawrence
  family: Carin
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/zhang19a/zhang19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
