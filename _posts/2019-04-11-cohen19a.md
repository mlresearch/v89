---
title: Learning Rules-First Classifiers
abstract: Complex classifiers may exhibit “embarassing” failures in cases where humans
  can easily provide a justified classification. Avoiding such failures is obviously
  of key importance. In this work, we focus on one such setting, where a label is
  perfectly predictable if the input contains certain features, or rules, and otherwise
  it is predictable by a linear classifier. We define a hypothesis class that captures
  this notion and determine its sample complexity. We also give evidence that efficient
  algorithms cannot achieve this sample complexity. We then derive a simple and efficient
  algorithm and show that its sample complexity is close to optimal, among efficient
  algorithms. Experiments on synthetic and sentiment analysis data demonstrate the
  efficacy of the method, both in terms of accuracy and interpretability.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: cohen19a
month: 0
tex_title: Learning Rules-First Classifiers
firstpage: 1398
lastpage: 1406
page: 1398-1406
order: 1398
cycles: false
bibtex_author: Cohen, Deborah and Daniely, Amit and Globerson, Amir and Elidan, Gal
author:
- given: Deborah
  family: Cohen
- given: Amit
  family: Daniely
- given: Amir
  family: Globerson
- given: Gal
  family: Elidan
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/cohen19a/cohen19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/cohen19a/cohen19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
