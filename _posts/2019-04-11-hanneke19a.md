---
title: Statistical Learning under Nonstationary Mixing Processes
abstract: We study a special case of the problem of statistical learning without the
  i.i.d. assumption. Specifically, we suppose a learning method is presented with
  a sequence of data points, and required to make a prediction (e.g., a classification)
  for each one, and can then observe the loss incurred by this prediction. We go beyond
  traditional analyses, which have focused on stationary mixing processes or nonstationary
  product processes, by combining these two relaxations to allow nonstationary mixing
  processes. We are particularly interested in the case of $\beta$-mixing processes,
  with the sum of changes in marginal distributions growing sublinearly in the number
  of samples. Under these conditions, we propose a learning method, and establish
  that for bounded VC subgraph classes, the cumulative excess risk grows sublinearly
  in the number of predictions, at a quantified rate.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: hanneke19a
month: 0
tex_title: Statistical Learning under Nonstationary Mixing Processes
firstpage: 1678
lastpage: 1686
page: 1678-1686
order: 1678
cycles: false
bibtex_author: Hanneke, Steve and Yang, Liu
author:
- given: Steve
  family: Hanneke
- given: Liu
  family: Yang
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/hanneke19a/hanneke19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
