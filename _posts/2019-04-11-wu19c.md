---
title: Differentiable Antithetic Sampling for Variance Reduction in Stochastic Variational
  Inference
abstract: Stochastic optimization techniques are standard in variational inference
  algorithms. These methods estimate gradients by approximating expectations with
  independent Monte Carlo samples. In this paper, we explore a technique that uses
  correlated, but more representative, samples to reduce estimator variance. Specifically,
  we show how to generate antithetic samples that match sample moments with the true
  moments of an underlying importance distribution. Combining a differentiable antithetic
  sampler with modern stochastic variational inference, we showcase the effectiveness
  of this approach for learning a deep generative model. An implementation is available
  at https://github.com/mhw32/antithetic-vae-public.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: wu19c
month: 0
tex_title: Differentiable Antithetic Sampling for Variance Reduction in Stochastic
  Variational Inference
firstpage: 2877
lastpage: 2886
page: 2877-2886
order: 2877
cycles: false
bibtex_author: Wu, Mike and Goodman, Noah and Ermon, Stefano
author:
- given: Mike
  family: Wu
- given: Noah
  family: Goodman
- given: Stefano
  family: Ermon
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/wu19c/wu19c.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/wu19c/wu19c-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
