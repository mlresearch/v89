---
title: 'Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive
  Flows'
abstract: We present Sequential Neural Likelihood (SNL), a new method for Bayesian
  inference in simulator models, where the likelihood is intractable but simulating
  data from the model is possible. SNL trains an autoregressive flow on simulated
  data in order to learn a model of the likelihood in the region of high posterior
  density. A sequential training procedure guides simulations and reduces simulation
  cost by orders of magnitude. We show that SNL is more robust, more accurate and
  requires less tuning than related neural-based methods, and we discuss diagnostics
  for assessing calibration, convergence and goodness-of-fit.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: papamakarios19a
month: 0
tex_title: 'Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive
  Flows'
firstpage: 837
lastpage: 848
page: 837-848
order: 837
cycles: false
bibtex_author: Papamakarios, George and Sterratt, David and Murray, Iain
author:
- given: George
  family: Papamakarios
- given: David
  family: Sterratt
- given: Iain
  family: Murray
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/papamakarios19a/papamakarios19a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
