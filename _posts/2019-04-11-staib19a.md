---
title: Distributionally Robust Submodular Maximization
abstract: Submodular functions have applications throughout machine learning, but
  in many settings, we do not have direct access to the underlying function f. We
  focus on stochastic functions that are given as an expectation of functions over
  a distribution P. In practice, we often have only a limited set of samples f_i from
  P. The standard approach indirectly optimizes f by maximizing the sum of f_i. However,
  this ignores generalization to the true (unknown) distribution. In this paper, we
  achieve better performance on the actual underlying function f by directly optimizing
  a combination of bias and variance. Algorithmically, we accomplish this by showing
  how to carry out distributionally robust optimization (DRO) for submodular functions,
  providing efficient algorithms backed by theoretical guarantees which leverage several
  novel contributions to the general theory of DRO. We also show compelling empirical
  evidence that DRO improves generalization to the unknown stochastic submodular function.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: staib19a
month: 0
tex_title: Distributionally Robust Submodular Maximization
firstpage: 506
lastpage: 516
page: 506-516
order: 506
cycles: false
bibtex_author: Staib, Matthew and Wilder, Bryan and Jegelka, Stefanie
author:
- given: Matthew
  family: Staib
- given: Bryan
  family: Wilder
- given: Stefanie
  family: Jegelka
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/staib19a/staib19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/staib19a/staib19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
