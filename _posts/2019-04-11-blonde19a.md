---
title: Sample-Efficient Imitation Learning via Generative Adversarial Nets
abstract: 'GAIL is a recent successful imitation learning architecture that exploits
  the adversarial training procedure introduced in GANs. Albeit successful at generating
  behaviours similar to those demonstrated to the agent, GAIL suffers from a high
  sample complexity in the number of interactions it has to carry out in the environment
  in order to achieve satisfactory performance. We dramatically shrink the amount
  of interactions with the environment necessary to learn well-behaved imitation policies,
  by up to several orders of magnitude. Our framework, operating in the model-free
  regime, exhibits a significant increase in sample-efficiency over previous methods
  by simultaneously a) learning a self-tuned adversarially-trained surrogate reward
  and b) leveraging an off-policy actor-critic architecture. We show that our approach
  is simple to implement and that the learned agents remain remarkably stable, as
  shown in our experiments that span a variety of continuous control tasks. Video
  visualisations available at: \url{https://youtu.be/-nCsqUJnRKU}.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: blonde19a
month: 0
tex_title: Sample-Efficient Imitation Learning via Generative Adversarial Nets
firstpage: 3138
lastpage: 3148
page: 3138-3148
order: 3138
cycles: false
bibtex_author: Blond\'{e}, Lionel and Kalousis, Alexandros
author:
- given: Lionel
  family: Blond√©
- given: Alexandros
  family: Kalousis
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/blonde19a/blonde19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/blonde19a/blonde19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
