---
title: Confidence Scoring Using Whitebox Meta-models with Linear Classifier Probes
abstract: We propose a novel confidence scoring mechanism for deep neural networks
  based on a two-model paradigm involving a base model and a meta-model. The confidence
  score is learned by the meta-model observing the base model succeeding/failing at
  its task. As features to the meta-model, we investigate linear classifier probes
  inserted between the various layers of the base model. Our experiments demonstrate
  that this approach outperforms multiple baselines in a filtering task, i.e., task
  of rejecting samples with low confidence. Experimental results are presented using
  CIFAR-10 and CIFAR-100 dataset with and without added noise. We discuss the importance
  of  confidence scoring to bridge the gap between experimental and real-world applications.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chen19c
month: 0
tex_title: Confidence Scoring Using Whitebox Meta-models with Linear Classifier Probes
firstpage: 1467
lastpage: 1475
page: 1467-1475
order: 1467
cycles: false
bibtex_author: Chen, Tongfei and Navratil, Jiri and Iyengar, Vijay and Shanmugam,
  Karthikeyan
author:
- given: Tongfei
  family: Chen
- given: Jiri
  family: Navratil
- given: Vijay
  family: Iyengar
- given: Karthikeyan
  family: Shanmugam
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/chen19c/chen19c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
