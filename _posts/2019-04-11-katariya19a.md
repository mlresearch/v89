---
title: Conservative Exploration using Interleaving
abstract: In many practical problems, a learning agent may want to learn the best
  action in hindsight without ever taking a bad action, which is much worse than a
  default production action. In general, this is impossible because the agent has
  to explore unknown actions, some of which can be bad, to learn better actions. However,
  when the actions are structured, this is possible if the unknown action can be evaluated
  by interleaving it with the default action. We formalize this concept as learning
  in stochastic combinatorial semi-bandits with exchangeable actions. We design efficient
  learning algorithms for this problem, bound their n-step regret, and evaluate them
  on both synthetic and real-world problems. Our real-world experiments show that
  our algorithms can learn to recommend K most attractive movies without ever making
  disastrous recommendations, both overall and subject to a diversity constraint.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: katariya19a
month: 0
tex_title: Conservative Exploration using Interleaving
firstpage: 954
lastpage: 963
page: 954-963
order: 954
cycles: false
bibtex_author: Katariya, Sumeet and Kveton, Branislav and Wen, Zheng and Potluru,
  Vamsi
author:
- given: Sumeet
  family: Katariya
- given: Branislav
  family: Kveton
- given: Zheng
  family: Wen
- given: Vamsi
  family: Potluru
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/katariya19a/katariya19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/katariya19a/katariya19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
