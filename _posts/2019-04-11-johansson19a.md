---
title: Support and Invertibility in Domain-Invariant Representations
abstract: Learning domain-invariant representations has become a popular approach
  to unsupervised domain adaptation and is often justified by invoking a particular
  suite of theoretical results. We argue that there are two significant flaws in such
  arguments. First, the results in question hold only for a fixed representation and
  do not account for information lost in non-invertible transformations. Second, domain
  invariance is often a far too strict requirement and does not always lead to consistent
  estimation, even under strong and favorable assumptions. In this work, we give generalization
  bounds for unsupervised domain adaptation that hold for any representation function
  by acknowledging the cost of non-invertibility. In addition, we show that penalizing
  distance between densities is often wasteful and propose a bound based on measuring
  the extent to which the support of the source domain covers the target domain. We
  perform experiments on well-known benchmarks that illustrate the short-comings of
  current standard practice.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: johansson19a
month: 0
tex_title: Support and Invertibility in Domain-Invariant Representations
firstpage: 527
lastpage: 536
page: 527-536
order: 527
cycles: false
bibtex_author: Johansson, Fredrik and Sontag, David and Ranganath, Rajesh
author:
- given: Fredrik
  family: Johansson
- given: David
  family: Sontag
- given: Rajesh
  family: Ranganath
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/johansson19a/johansson19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/johansson19a/johansson19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
