---
title: Defending against Whitebox Adversarial Attacks via Randomized Discretization
abstract: 'Adversarial perturbations dramatically decrease the accuracy of state-of-the-art
  image classifiers. In this paper, we propose and analyze a simple and computationally
  efficient defense strategy: inject random Gaussian noise, discretize each pixel,
  and then feed the result into any pre-trained classifier. Theoretically, we show
  that our randomized discretization strategy reduces the KL divergence between original
  and adversarial inputs, leading to a lower bound on the classification accuracy
  of any classifier against any (potentially whitebox) $L_{\infty}$-bounded adversarial
  attack. Empirically, we evaluate our defense on adversarial examples generated by
  a strong iterative PGD attack. On ImageNet, our defense is more robust than adversarially-trained
  networks and the winning defenses of the NIPS 2017 Adversarial Attacks & Defenses
  competition.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhang19b
month: 0
tex_title: Defending against Whitebox Adversarial Attacks via Randomized Discretization
firstpage: 684
lastpage: 693
page: 684-693
order: 684
cycles: false
bibtex_author: Zhang, Yuchen and Liang, Percy
author:
- given: Yuchen
  family: Zhang
- given: Percy
  family: Liang
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/zhang19b/zhang19b.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
