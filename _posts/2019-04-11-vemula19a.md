---
title: 'Contrasting Exploration in Parameter and Action Space: A Zeroth-Order Optimization
  Perspective'
abstract: Black-box optimizers that explore in parameter space have often been shown
  to outperform more sophisticated action space exploration methods developed specifically
  for the reinforcement learning problem. We examine these black-box methods closely
  to identify situations in which they are worse than action space exploration methods
  and those in which they are superior. Through simple theoretical analyses, we prove
  that complexity of exploration in parameter space depends on the dimensionality
  of parameter space, while complexity of exploration in action space depends on both
  the dimensionality of action space and horizon length. This is also demonstrated
  empirically by comparing simple exploration methods on several model problems, including
  Contextual Bandit, Linear Regression and Reinforcement Learning in continuous control.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: vemula19a
month: 0
tex_title: 'Contrasting Exploration in Parameter and Action Space: A Zeroth-Order
  Optimization Perspective'
firstpage: 2926
lastpage: 2935
page: 2926-2935
order: 2926
cycles: false
bibtex_author: Vemula, Anirudh and Sun, Wen and Bagnell, J.
author:
- given: Anirudh
  family: Vemula
- given: Wen
  family: Sun
- given: J.
  family: Bagnell
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/vemula19a/vemula19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/vemula19a/vemula19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
