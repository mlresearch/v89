---
title: Stochastic Gradient Descent with Exponential Convergence Rates of Expected
  Classification Errors
abstract: We consider stochastic gradient descent and its averaging variant for binary
  classification problems in a reproducing kernel Hilbert space. In traditional analysis
  using a consistency property of loss functions, it is known that the expected classification
  error converges more slowly than the expected risk even when assuming a low-noise
  condition on the conditional label probabilities. Consequently, the resulting rate
  is sublinear.  Therefore, it is important to consider whether much faster convergence
  of the expected classification error can be achieved. In recent research, an exponential
  convergence rate for stochastic gradient descent was shown under a strong low-noise
  condition but provided theoretical analysis was limited to the square loss function,
  which is somewhat inadequate for binary classification tasks. In this paper,  we
  show an exponential convergence of the expected classification error in the final
  phase of the stochastic gradient descent for a wide class of differentiable convex
  loss functions under similar assumptions. As for the averaged stochastic gradient
  descent, we show that the same convergence rate holds from the early phase of training.
  In experiments, we verify our analyses on the $L_2$-regularized logistic regression.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: nitanda19a
month: 0
tex_title: Stochastic Gradient Descent with Exponential Convergence Rates of Expected
  Classification Errors
firstpage: 1417
lastpage: 1426
page: 1417-1426
order: 1417
cycles: false
bibtex_author: Nitanda, Atsushi and Suzuki, Taiji
author:
- given: Atsushi
  family: Nitanda
- given: Taiji
  family: Suzuki
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/nitanda19a/nitanda19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/nitanda19a/nitanda19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
