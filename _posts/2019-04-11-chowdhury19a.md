---
title: Online Learning in Kernelized Markov Decision Processes
abstract: We consider online learning for minimizing regret in unknown, episodic Markov
  decision processes (MDPs) with continuous states and actions. We develop variants
  of the UCRL and posterior sampling algorithms that employ non-parametric Gaussian
  process priors to generalize across the state and action spaces. When the transition
  and reward functions of the true MDP are members of the associated Reproducing Kernel
  Hilbert Spaces of functions induced by symmetric psd kernels, we show that the algorithms
  en-joy sublinear regret bounds. The bounds are in terms of explicit structural parameters
  of the kernels, namely a novel generalization of the information gain metric from
  kernelized bandit, and highlight the influence of transition and reward function
  structure on the learning performance. Our results are applicable to multi-dimensional
  state and action spaces with composite kernel structures, and generalize results
  from the literature on kernelized bandits, and the adaptive control of parametric
  linear dynamical systems with quadratic costs.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: chowdhury19a
month: 0
tex_title: Online Learning in Kernelized Markov Decision Processes
firstpage: 3197
lastpage: 3205
page: 3197-3205
order: 3197
cycles: false
bibtex_author: Chowdhury, Sayak Ray and Gopalan, Aditya
author:
- given: Sayak Ray
  family: Chowdhury
- given: Aditya
  family: Gopalan
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/chowdhury19a/chowdhury19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/chowdhury19a/chowdhury19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
