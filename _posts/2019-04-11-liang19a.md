---
title: Fisher-Rao Metric, Geometry, and Complexity of Neural Networks
abstract: We study the relationship between geometry and capacity measures for deep
  neural networks from an invariance viewpoint. We introduce a new notion of capacity
  — the Fisher-Rao norm — that possesses desirable invariance properties and is motivated
  by Information Geometry. We discover an analytical characterization of the new capacity
  measure, through which we establish norm-comparison inequalities and further show
  that the new measure serves as an umbrella for several existing norm-based complexity
  measures. We discuss upper bounds on the generalization error induced by the proposed
  measure. Extensive numerical experiments on CIFAR-10 support our theoretical findings.
  Our theoretical analysis rests on a key structural lemma about partial derivatives
  of multi-layer rectifier networks.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: liang19a
month: 0
tex_title: Fisher-Rao Metric, Geometry, and Complexity of Neural Networks
firstpage: 888
lastpage: 896
page: 888-896
order: 888
cycles: false
bibtex_author: Liang, Tengyuan and Poggio, Tomaso and Rakhlin, Alexander and Stokes,
  James
author:
- given: Tengyuan
  family: Liang
- given: Tomaso
  family: Poggio
- given: Alexander
  family: Rakhlin
- given: James
  family: Stokes
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/liang19a/liang19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/liang19a/liang19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
