---
title: Fast and Faster Convergence of SGD for Over-Parameterized Models and an Accelerated
  Perceptron
abstract: Modern machine learning focuses on highly expressive models that are able
  to fit or interpolate the data completely,  resulting in zero training loss. For
  such models, we show that the stochastic gradients of common loss functions satisfy
  a strong growth condition. Under this condition, we prove that constant step-size
  stochastic gradient descent (SGD) with Nesterov acceleration matches the convergence
  rate of the deterministic accelerated method for both convex and strongly-convex
  functions. We also show that this condition implies that SGD can find a first-order
  stationary point as efficiently as full gradient descent in non-convex settings.
  Under interpolation, we further show that all smooth loss functions with a finite-sum
  structure satisfy a weaker growth condition. Given this weaker condition, we prove
  that SGD with a constant step-size attains the deterministic convergence rate in
  both the strongly-convex and convex settings. Under additional assumptions, the
  above results enable us to prove an $O(1/k^2)$ mistake bound for $k$ iterations
  of a stochastic perceptron algorithm using the squared-hinge loss. Finally, we validate
  our theoretical findings with experiments on synthetic and real datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: vaswani19a
month: 0
tex_title: Fast and Faster Convergence of SGD for Over-Parameterized Models and an
  Accelerated Perceptron
firstpage: 1195
lastpage: 1204
page: 1195-1204
order: 1195
cycles: false
bibtex_author: Vaswani, Sharan and Bach, Francis and Schmidt, Mark
author:
- given: Sharan
  family: Vaswani
- given: Francis
  family: Bach
- given: Mark
  family: Schmidt
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/vaswani19a/vaswani19a.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/vaswani19a/vaswani19a-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
