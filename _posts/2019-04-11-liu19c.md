---
title: Amortized Variational Inference with Graph Convolutional Networks for Gaussian
  Processes
abstract: 'GP Inference on large datasets is computationally expensive, especially
  when the observation likelihood is non-Gaussian. To reduce the computation, many
  recent variational inference methods define the variational distribution based on
  a small number of inducing points. These methods have a hard tradeoff between distribution
  flexibility and computational efficiency. In this paper, we focus on the approximation
  of GP posterior at a local level: we define a reusable template to approximate the
  posterior at neighborhoods while maintaining a global approximation. We first construct
  a variational distribution such that the inference for a data point considers only
  its neighborhood, thereby separating the calculation for each data point. We then
  train Graph Convolutional Networks as a reusable model to run inference for each
  data point. Comparing to previous methods, our method greatly reduces the number
  of parameters and also the number of optimization iterations. In empirical evaluations,
  the proposed method significantly speeds up the inference and often gets more accurate
  results than competing methods.'
layout: inproceedings
series: Proceedings of Machine Learning Research
id: liu19c
month: 0
tex_title: Amortized Variational Inference with Graph Convolutional Networks for Gaussian
  Processes
firstpage: 2291
lastpage: 2300
page: 2291-2300
order: 2291
cycles: false
bibtex_author: Liu, Linfeng and Liu, Liping
author:
- given: Linfeng
  family: Liu
- given: Liping
  family: Liu
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/liu19c/liu19c.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
