---
title: Decentralized Gradient Tracking for Continuous DR-Submodular Maximization
abstract: In this paper, we focus on the continuous DR-submodular maximization over
  a network. By using the gradient tracking technique, two decentralized algorithms
  are proposed for deterministic and stochastic settings, respectively. The proposed
  methods attain the $\epsilon$-accuracy tight approximation ratio for monotone continuous
  DR-submodular functions in only $O(1/\epsilon)$ and $\tilde{O}(1/\epsilon)$ rounds
  of communication, respectively, which are superior to the state-of-the-art. Our
  numerical results show that the proposed methods outperform existing decentralized
  methods in terms of both computation and communication complexity.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: xie19b
month: 0
tex_title: Decentralized Gradient Tracking for Continuous DR-Submodular Maximization
firstpage: 2897
lastpage: 2906
page: 2897-2906
order: 2897
cycles: false
bibtex_author: Xie, Jiahao and Zhang, Chao and Shen, Zebang and Mi, Chao and Qian,
  Hui
author:
- given: Jiahao
  family: Xie
- given: Chao
  family: Zhang
- given: Zebang
  family: Shen
- given: Chao
  family: Mi
- given: Hui
  family: Qian
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of the Twenty-Second International Conference on Artificial Intelligence and Statistics
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/xie19b/xie19b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/xie19b/xie19b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
