---
title: 'Universal Hypothesis Testing with Kernels: Asymptotically Optimal Tests for
  Goodness of Fit'
abstract: We characterize the asymptotic performance of nonparametric goodness of
  fit testing. The exponential decay rate of the type-II error probability is used
  as the asymptotic performance metric, and a test is optimal if it achieves the maximum
  rate subject to a constant level constraint on the type-I error probability. We
  show that two classes of Maximum Mean Discrepancy (MMD) based tests attain this
  optimality on $\mathbb R^d$, while the quadratic-time Kernel Stein Discrepancy (KSD)
  based tests achieve the maximum exponential decay rate under a relaxed level constraint.
  Under the same performance metric, we proceed to show that the quadratic-time MMD
  based two-sample tests are also optimal for general two-sample problems, provided
  that kernels are bounded continuous and characteristic. Key to our approach are
  Sanovâ€™s theorem from large deviation theory and the weak metrizable properties of
  the MMD and KSD.
layout: inproceedings
series: Proceedings of Machine Learning Research
id: zhu19b
month: 0
tex_title: 'Universal Hypothesis Testing with Kernels: Asymptotically Optimal Tests
  for Goodness of Fit'
firstpage: 1544
lastpage: 1553
page: 1544-1553
order: 1544
cycles: false
bibtex_author: Zhu, Shengyu and Chen, Biao and Yang, Pengfei and Chen, Zhitang
author:
- given: Shengyu
  family: Zhu
- given: Biao
  family: Chen
- given: Pengfei
  family: Yang
- given: Zhitang
  family: Chen
date: 2019-04-11
address: 
publisher: PMLR
container-title: Proceedings of Machine Learning Research
volume: '89'
genre: inproceedings
issued:
  date-parts:
  - 2019
  - 4
  - 11
pdf: http://proceedings.mlr.press/v89/zhu19b/zhu19b.pdf
extras:
- label: Supplementary PDF
  link: http://proceedings.mlr.press/v89/zhu19b/zhu19b-supp.pdf
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
